{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Dropout, BatchNormalization, Reshape, Flatten, RepeatVector\n",
    "from keras.layers import Lambda, Dense, Input, Conv2D, MaxPool2D, UpSampling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
    "\n",
    "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
    "y_test_cat  = to_categorical(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "batch_shape = (batch_size, 28, 28, 1)\n",
    "latent_dim = 2\n",
    "num_classes = 10\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train[(y_train_cat[:,0]==1) |(y_train_cat[:,1]==1)]\n",
    "# x_traiy_train_cat= y_train_cat[(y_train_cat[:,0]==1) |(y_train_cat[:,1]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x, y):\n",
    "    n_batches = x.shape[0] // batch_size\n",
    "    while(True):\n",
    "        for i in range(n_batches):\n",
    "            yield x[batch_size*i: batch_size*(i+1)], y[batch_size*i: batch_size*(i+1)]\n",
    "        idxs = np.random.permutation(y.shape[0])\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "\n",
    "\n",
    "train_batches_it = gen_batch(x_train, y_train_cat)\n",
    "test_batches_it  = gen_batch(x_test,  y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(tf.float32, shape=(None, 28, 28, 1),   name='image')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, num_classes), name='labels')\n",
    "z_ = tf.placeholder(tf.float32, shape=(None, latent_dim),  name='z')\n",
    "\n",
    "img = Input(tensor=x_)\n",
    "lbl = Input(tensor=y_)\n",
    "z   = Input(tensor=z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('generator'):\n",
    "    x = concatenate([z, lbl])\n",
    "    x = Dense(7*7*64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Reshape((7, 7, 64))(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    generated = Conv2D(1, kernel_size=(5, 5), activation='sigmoid', padding='same')(x)\n",
    "generator = Model([z, lbl], generated, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_units_to_conv2d(conv2, units):\n",
    "    dim1 = int(conv2.shape[1])\n",
    "    dim2 = int(conv2.shape[2])\n",
    "    dimc = int(units.shape[1])\n",
    "    repeat_n = dim1*dim2\n",
    "    units_repeat = RepeatVector(repeat_n)(lbl)\n",
    "    units_repeat = Reshape((dim1, dim2, dimc))(units_repeat)\n",
    "    return concatenate([conv2, units_repeat])\n",
    "\n",
    "\n",
    "with tf.variable_scope('discrim'):\n",
    "    x = Conv2D(128, kernel_size=(7, 7), strides=(2, 2), padding='same')(img)\n",
    "    x = add_units_to_conv2d(x, lbl)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = MaxPool2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    l = Conv2D(128, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU()(l)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    h = Flatten()(x)\n",
    "    d = Dense(1, activation='sigmoid')(h)\n",
    "discrim = Model([img, lbl], d, name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_z = generator([z, lbl])\n",
    "\n",
    "discr_img   = discrim([img, lbl])\n",
    "discr_gen_z = discrim([generated_z, lbl])\n",
    "\n",
    "gan_model = Model([z, lbl], discr_gen_z, name='GAN')\n",
    "gan   = gan_model([z, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dis_img   = tf.reduce_mean(-tf.log(discr_img + 1e-10))\n",
    "log_dis_gen_z = tf.reduce_mean(-tf.log(1. - discr_gen_z + 1e-10))\n",
    "\n",
    "L_gen = -log_dis_gen_z\n",
    "L_dis = 0.5*(log_dis_gen_z + log_dis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_gen = tf.train.RMSPropOptimizer(0.0003)\n",
    "optimizer_dis = tf.train.RMSPropOptimizer(0.0001)\n",
    "\n",
    "# Переменные генератора и дискриминаторы (отдельно) для оптимизаторов\n",
    "generator_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "discrim_vars   = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discrim\")\n",
    "\n",
    "step_gen = optimizer_gen.minimize(L_gen, var_list=generator_vars)\n",
    "step_dis = optimizer_dis.minimize(L_dis, var_list=discrim_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг обучения генератора\n",
    "def step(image, label, zp):\n",
    "    l_dis, _ = sess.run([L_dis, step_gen], feed_dict={z:zp, lbl:label, img:image, K.learning_phase():1})\n",
    "    return l_dis\n",
    "\n",
    "# Шаг обучения дискриминатора\n",
    "def step_d(image, label, zp):\n",
    "    l_dis, _ = sess.run([L_dis, step_dis], feed_dict={z:zp, lbl:label, img:image, K.learning_phase():1})\n",
    "    return l_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массивы, в которые будем сохранять результаты, для последующей визуализации\n",
    "figs = [[] for x in range(num_classes)]\n",
    "periods = []\n",
    "\n",
    "save_periods = list(range(100)) + list(range(100, 1000, 10))\n",
    "\n",
    "n = 15 # Картинка с 15x15 цифр\n",
    "from scipy.stats import norm\n",
    "# Так как сэмплируем из N(0, I), то сетку узлов, в которых генерируем цифры, берем из обратной функции распределения\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "def draw_manifold(label, show=True):\n",
    "    # Рисование цифр из многообразия\n",
    "    figure = np.zeros((28 * n, 28 * n))\n",
    "    input_lbl = np.zeros((1, 10))\n",
    "    input_lbl[0, label] = 1.\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            z_sample[:, :2] = np.array([[xi, yi]])\n",
    "\n",
    "            x_generated = sess.run(generated_z, feed_dict={z:z_sample, lbl:input_lbl, K.learning_phase():0})\n",
    "            digit = x_generated[0].squeeze()\n",
    "            figure[i * 28: (i + 1) * 28,\n",
    "                   j * 28: (j + 1) * 28] = digit\n",
    "    if show:\n",
    "        # Визуализация\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(figure, cmap='Greys')\n",
    "        plt.grid(False)\n",
    "        ax = plt.gca()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "    return figure\n",
    "\n",
    "\n",
    "n_compare = 10\n",
    "def on_n_period(period):\n",
    "    clear_output() # Не захламляем output\n",
    "\n",
    "    # Рисование многообразия для рандомного y\n",
    "    draw_lbl = np.random.randint(0, num_classes)    \n",
    "    print(draw_lbl)\n",
    "    for label in range(num_classes):\n",
    "        figs[label].append(draw_manifold(label, show=label==draw_lbl))\n",
    "\n",
    "    periods.append(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (256, 10) for Tensor 'labels_1:0', which has shape '(?, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-ac1306e144f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Шаги обучения дискриминатора\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0ml_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mb0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mzp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-a94ea8bc467d>\u001b[0m in \u001b[0;36mstep_d\u001b[1;34m(image, label, zp)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Шаг обучения дискриминатора\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstep_d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0ml_dis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL_dis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_dis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mzp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ml_dis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (256, 10) for Tensor 'labels_1:0', which has shape '(?, 2)'"
     ]
    }
   ],
   "source": [
    "batches_per_period = 20 # Как часто сохранять картинки\n",
    "k_step = 5 # Количество шагов, которые могут делать дискриминатор и генератор во внутреннем цикле\n",
    "\n",
    "for i in range(5000):\n",
    "    print('.', end='')\n",
    "    # Достанем новый батч\n",
    "    b0, b1 = next(train_batches_it)\n",
    "    zp = np.random.randn(batch_size, latent_dim)\n",
    "    # Шаги обучения дискриминатора\n",
    "    for j in range(k_step):\n",
    "        l_d = step_d(b0, b1, zp)\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "        if l_d < 1.0:\n",
    "            break\n",
    "\n",
    "    # Шаги обучения генератора\n",
    "    for j in range(k_step):\n",
    "        l_d = step(b0, b1, zp)\n",
    "        if l_d > 0.4:\n",
    "            break\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "\n",
    "    # Периодическое рисование результата\n",
    "    if not i % batches_per_period:\n",
    "        period = i // batches_per_period\n",
    "        if period in save_periods:\n",
    "            on_n_period(period)\n",
    "        print(l_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "\n",
    "def make_2d_figs_gif(figs, periods, c, fname, fig, batches_per_period): \n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=1, clip=False)\n",
    "    im = plt.imshow(np.zeros((28,28)), cmap='Greys', norm=norm)\n",
    "    plt.grid(None)\n",
    "    plt.title(\"Label: {}\\nBatch: {}\".format(c, 0))\n",
    "\n",
    "    def update(i):\n",
    "        im.set_array(figs[i])\n",
    "        im.axes.set_title(\"Label: {}\\nBatch: {}\".format(c, periods[i]*batches_per_period))\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        return im\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=range(len(figs)), interval=100)\n",
    "    anim.save(fname, dpi=80, writer='imagemagick')\n",
    "\n",
    "for label in range(num_classes):\n",
    "    make_2d_figs_gif(figs[label], periods, label, \"./figs4_5/manifold_{}.gif\".format(label), plt.figure(figsize=(10,10)), batches_per_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
