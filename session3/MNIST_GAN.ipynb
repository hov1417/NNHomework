{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = np.load(\"mnist.npz\").items()\n",
    "_X = load[0][1]\n",
    "_Y = load[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _X[(_Y == 0) | (_Y == 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14780, 784) 0.0 0.12147417153600294 1.0\n"
     ]
    }
   ],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inptDim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(inptDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import FloatSlider, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a,b,c,d,e):\n",
    "    plt.imshow(pca.inverse_transform([a,b,c,d,e]).reshape((28,28)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f91b296255455c913f7f380e0a3351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='a', max=10.0, min=-10.0), FloatSlider(value=0.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=interact(f, a=FloatSlider(min=-10, max=10, step=0.1, continuous_update=True),\n",
    "             b=FloatSlider(min=-10, max=10, step=0.1, continuous_update=True),\n",
    "             c=FloatSlider(min=-10, max=10, step=0.1, continuous_update=True),\n",
    "             d=FloatSlider(min=-10, max=10, step=0.1, continuous_update=True),\n",
    "             e=FloatSlider(min=-10, max=10, step=0.1, continuous_update=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695e69f8a32249baa124aa6ef18baf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='a', max=10.0, min=-10.0), FloatSlider(value=0.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(f, a=(-10,10,0.1),\n",
    "            b=(-10,10,0.1),\n",
    "            c=(-10,10,0.1),\n",
    "            d=(-10,10,0.1),\n",
    "            e=(-10,10,0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.initializers.random_uniform(-0.01,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inpt, reuse, name):\n",
    "    with tf.variable_scope(\"Discriminator\", reuse=reuse):\n",
    "# #         dl1 = tf.layers.dense(inpt, 784, activation=tf.nn.relu, name=\"dl1\", kernel_initializer=init)\n",
    "# #         dl1 = tf.layers.conv2d(inpt, 30, 5, activation=tf.nn.relu, name=\"dl1\", kernel_initializer=init)\n",
    "# #         dl2 = tf.layers.max_pooling2d(dl1, 2, 2, name=\"dl2\")\n",
    "        \n",
    "# #         dl3 = tf.layers.dropout(dl2, name=\"dl3\")\n",
    "        \n",
    "# #         dl4 = tf.layers.conv2d(dl3, 20, 5, activation=tf.nn.relu, name=\"dl4\", kernel_initializer=init)\n",
    "# #         dl5p= tf.layers.max_pooling2d(dl4, 2, 2, name=\"dl5p\")\n",
    "# #         dl5f= tf.layers.flatten(dl5p)\n",
    "        \n",
    "#         dl6 = tf.layers.dense(inpt, 200, activation=tf.nn.relu, name=\"dl6\", kernel_initializer=init)\n",
    "#         dl6d= tf.layers.dropout(dl6, name=\"dl6d\")\n",
    "#         dl7 = tf.layers.dense(dl6d, 100, activation=tf.nn.relu, name=\"dl7\", kernel_initializer=init)\n",
    "#         dl8 = tf.layers.dense( dl7, 10, activation=tf.nn.relu, name=\"dl8\", kernel_initializer=init)\n",
    "#         dis = tf.layers.dense( dl8, 1, name=\"dis\")\n",
    "#         prob= tf.sigmoid(dis, name)\n",
    "        dl1 = tf.layers.conv2d(inpt, 30, 5, activation=tf.nn.relu, name=\"dl1\", kernel_initializer=init)\n",
    "        dl2 = tf.layers.max_pooling2d(dl1, 2, 2, name=\"dl2\")\n",
    "        \n",
    "        dl3 = tf.layers.dropout(dl2, name=\"dl3\")\n",
    "        \n",
    "        dl4 = tf.layers.conv2d(dl3, 20, 5, activation=tf.nn.relu, name=\"dl4\", kernel_initializer=init)\n",
    "        dl5p= tf.layers.max_pooling2d(dl4, 2, 2, name=\"dl5p\")\n",
    "        dl5f= tf.layers.flatten(dl5p)\n",
    "        \n",
    "        dl6 = tf.layers.dense(dl5f, 200, activation=tf.nn.relu, name=\"dl6\", kernel_initializer=init)\n",
    "        dl7 = tf.layers.dense( dl6, 100, activation=tf.nn.relu, name=\"dl7\", kernel_initializer=init)\n",
    "        dl8 = tf.layers.dense( dl7, 10, activation=tf.nn.relu, name=\"dl8\", kernel_initializer=init)\n",
    "        dis = tf.layers.dense( dl8, 1, name=\"dis\")\n",
    "        prob= tf.sigmoid(dis, name)\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseDim = 100\n",
    "# inX = tf.placeholder(tf.float32, shape=[None, inptDim], name=\"X\")\n",
    "inX = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name=\"X\")\n",
    "z  = tf.placeholder(tf.float32, shape=[None, noiseDim], name=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = discriminator(inX, False, \"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Generator\"):\n",
    "\n",
    "#     gl1 = tf.layers.dense(z,   100, activation=tf.nn.leaky_relu, name=\"gl1\", kernel_initializer=init)\n",
    "#     gl2 = tf.layers.dense(gl1, 120, activation=tf.nn.leaky_relu, name=\"gl2\", kernel_initializer=init)\n",
    "#     gl3 = tf.layers.dense(gl2, 150, activation=tf.nn.leaky_relu, name=\"gl3\", kernel_initializer=init)\n",
    "#     gen = tf.layers.dense(gl3, inptDim, activation=tf.nn.leaky_relu, name=\"gen\", kernel_initializer=init)\n",
    "    \n",
    "    gl1 = tf.layers.dense(z,   1000, activation=tf.nn.leaky_relu, name=\"gl1\", kernel_initializer=init)\n",
    "    gl2 = tf.layers.dense(gl1, 800, activation=tf.nn.leaky_relu, name=\"gl2\", kernel_initializer=init)\n",
    "    gl3 = tf.layers.dense(gl2, 784, activation=tf.nn.leaky_relu, name=\"gl3\", kernel_initializer=init)\n",
    "    gl4 = tf.layers.dense(gl3, 784, activation=tf.nn.sigmoid, name=\"gl4\", kernel_initializer=init)\n",
    "    gen = tf.reshape(gl4, (-1, 28, 28, 1), name=\"gen\")\n",
    "#     gen = tf.reshape(gl4, (-1, 28, 28, 1), name=\"gen\")\n",
    "#     gen = tf.layers.dense(gl4, 2, name=\"gen\")\n",
    "\n",
    "combined = discriminator(gen, True, \"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_vars  = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss = tf.reduce_mean(tf.log(1 - combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloss = - tf.reduce_mean(tf.log(dis) + tf.log(1 - combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('log/')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.train.AdamOptimizer(1e-3).minimize(gloss, var_list=gen_vars)\n",
    "train_dis = tf.train.AdamOptimizer(1e-3).minimize(dloss, var_list=disc_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseGenerator(batch_size, mean_rng=[-100, 100]):\n",
    "    while True:\n",
    "        mask = np.random.randint(0, 2, (batch_size, 1))\n",
    "        yield np.random.multivariate_normal(np.zeros(noiseDim), np.identity(noiseDim), batch_size) * mask + \\\n",
    "        np.random.multivariate_normal(4 * np.ones(noiseDim), np.identity(noiseDim), batch_size) * (1 - mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    clear_output(wait=True)\n",
    "    fig = plt.figure(figsize=(15,20))\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(-glh, label=\"generator loss\")\n",
    "    plt.plot( dlh, label=\"discriminator loss\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "#     plt.title(\"Generated numbers\")\n",
    "#     plt.grid(None)\n",
    "#     for i in range(5):\n",
    "#         plt.figure(figsize=(5,5))\n",
    "# #         plt.subplot(10*2, 10, 100 + i)\n",
    "#         plt.imshow(generated[i].reshape((28, 28)))\n",
    "\n",
    "\n",
    "#     genT = pca.inverse_transform(generated[:2])\n",
    "    \n",
    "    genT = (generated)\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.imshow(genT[0].reshape((28, 28)))\n",
    "    plt.subplot(224)\n",
    "    plt.imshow(genT[1].reshape((28, 28)))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info():\n",
    "    print(\"gen:\", -gen_train_err)\n",
    "    print(\"dis:\", dis_train_err)\n",
    "    print(\"epoch:\", len(glosshist))\n",
    "    print(\"distance:\", dist)\n",
    "    print(\"has nan:\", np.any(np.isnan(generated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"sess\" in dir():\n",
    "    sess.close()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxIter = 10000\n",
    "eps = 0\n",
    "batch_size = 256\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainData = pca.transform(data)\n",
    "trainData = data.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.68824774 1.3804135\n",
      "10\n",
      "-0.23120517 0.9421281\n",
      "10\n",
      "-0.006477599 0.17516287\n",
      "10\n",
      "-1.082663e-06 6.883357e-05\n",
      "10\n",
      "-9.359792e-08 1.3457614e-07\n",
      "10\n",
      "0.0 9.75255e-05\n",
      "0.0 0.00038935765\n",
      "0.0 4.847331e-05\n",
      "0.0 4.6280547e-06\n",
      "0.0 5.2901066e-07\n",
      "0.0 8.0094125e-08\n",
      "0.0 2.002345e-08\n",
      "0.0 1.0244554e-08\n",
      "0.0 7.916245e-09\n",
      "0.0 6.5192616e-09\n",
      "0.0 6.0535994e-09\n",
      "0.0 5.5879377e-09\n",
      "0.0 5.1222764e-09\n",
      "0.0 4.6566146e-09\n",
      "0.0 4.6566146e-09\n",
      "0.0 4.6566146e-09\n",
      "0.0 4.190953e-09\n",
      "0.0 4.190953e-09\n",
      "0.0 4.190953e-09\n",
      "0.0 4.190953e-09\n",
      "0.0 4.190953e-09\n",
      "0.0 3.725291e-09\n",
      "0.0 3.725291e-09\n",
      "0.0 3.725291e-09\n",
      "0.0 3.725291e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 3.25963e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n",
      "0.0 2.7939684e-09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-6dd6bac85dbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         _, dis_train_err, gen_train_err = sess.run([train_dis, dloss, gloss],\n\u001b[1;32m---> 15\u001b[1;33m                                                    feed_dict={inX: X, z: next(noise1)})\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_train_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_train_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "glosshist=[]\n",
    "dlosshist=[]\n",
    "\n",
    "noise1 = noiseGenerator(batch_size, [-10, 10])\n",
    "noise2 = noiseGenerator(2, [-12, 12])\n",
    "\n",
    "dist = 100\n",
    "while True:#dist > eps:\n",
    "    X = trainData[np.random.choice(len(trainData), batch_size)]\n",
    "\n",
    "    for i in range(k):\n",
    "        _, dis_train_err = sess.run([train_dis, dloss], feed_dict={inX: X, z: next(noise1)})\n",
    "    while True:\n",
    "        _, dis_train_err, gen_train_err = sess.run([train_dis, dloss, gloss],\n",
    "                                                   feed_dict={inX: X, z: next(noise1)})\n",
    "        i+=1\n",
    "        print(gen_train_err, dis_train_err)\n",
    "        if gen_train_err != 0 or np.isnan(gen_train_err):\n",
    "            break;\n",
    "            \n",
    "    print(i)\n",
    "            \n",
    "#     print(\"dis trained\")\n",
    "    _, gen_train_err = sess.run([train_gen, gloss], feed_dict={inX: X, z: next(noise1)})\n",
    "\n",
    "    glosshist.append(gen_train_err)\n",
    "    dlosshist.append(dis_train_err)\n",
    "\n",
    "    if len(glosshist)%20 == 0:\n",
    "#         out = sess.run(dis, feed_dict={inX: l2})\n",
    "        generated = sess.run(gen, feed_dict={z: next(noise2)})\n",
    "        \n",
    "        dist = np.abs(glosshist[-1]-glosshist[-2]) + np.abs(dlosshist[-1]-dlosshist[-2])\n",
    "        \n",
    "        glh = np.array(glosshist[-500:])\n",
    "        dlh = np.array(dlosshist[-500:])\n",
    "        plot()\n",
    "        info()\n",
    "#     print(sess.run(gen_vars[1])[:10])\n",
    "#     print(sess.run(disc_vars[1])[:10])\n",
    "    if len(glosshist) >= maxIter:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.587937e-09)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_train_err, dis_train_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glosshist, dlosshist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise3 = noiseGenerator(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genT = pca.inverse_transform(sess.run(gen, feed_dict={z: next(noise3)}))\n",
    "genT = sess.run(gen, feed_dict={z: next(noise3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10, figsize=(11, 11))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax[i, j].xaxis.set_major_locator(plt.NullLocator())\n",
    "        ax[i, j].yaxis.set_major_locator(plt.NullLocator())\n",
    "        ax[i, j].imshow(genT[i*10 + j].reshape((28, 28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
